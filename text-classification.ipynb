{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#import advertools as adv\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import ExcelWriter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download_shell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open(\"/Users/ssvalipour/Downloads/text classification/English/english10k_tweets.json\",encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(columns=['tweet_id','tweet_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                           tweet_text\n",
      "tweet_id                                                             \n",
      "815331870015627265  Wind 1,4 m/s ENE. Barometer 1003,2 hPa, Fallin...\n",
      "815332374909222912                               @pasdcheval i did it\n",
      "815332387496357889       Happy New Year 2017! https://t.co/UFob5hzO5o\n",
      "815332527254732800                         Happy new Year from sweden\n",
      "815332597886840834                              Happy New Years!!!! üí´\n",
      "815333076070965249  @nelson02051 @Arianna483 he is a hunk papi now...\n",
      "815333369751990276                       @ThatManMatt Happy new year!\n",
      "815333438374998016  @sarahchang Happy New Year and happy 300 years...\n",
      "815333549289209856  Not only have the fireworks been going off sin...\n",
      "815333756932333569  I know it probably didn't come out in January....\n",
      "815333875077566465     when you p r o g r a m https://t.co/HXgSMwIpqs\n",
      "815333969801728001   Happy New Years, bitches https://t.co/80VJ4w3TGt\n",
      "815334054790893568          @KoponenPetteri SAME to YOU &amp; FAMILY!\n",
      "815334109656522753  Guess who been on stage @saaraaalto #Suomi100 ...\n",
      "815334157626834944           Happy new year üòç https://t.co/IwTCbUcmLj\n",
      "815334231454994432  Happy New Year ya'll üéá @BTS_twt https://t.co/6...\n",
      "815334667171794944  @AlfredoFlores Same, I saw Justin for the firs...\n",
      "815335361538883584  Gott nytt #4\\nImperial ftw... - Drinking a Ver...\n",
      "815335396745900032  Wind 3,1 m/s NNE. Barometer 1003,0 hPa, Fallin...\n",
      "815335415708192768  101 users and 114 tweets (31 RTs) in 1 week ma...\n",
      "815335418652540928  2 verified accounts helped to turn 'Gott Nytt ...\n",
      "815335693539045376  ‚ú®üí• Happy New Year Everyone ‚òÑÔ∏èüí• @ Varatunveien ...\n",
      "815335831011467265  @OMGitsfirefoxx the last thing I said in 2016 ...\n",
      "815336030014414848                                 Happy new year! üòöüéâ\n",
      "815336278938030080  Sista godsaken. @ My Home Tv4B https://t.co/UA...\n",
      "815336343941300228  May the new year bring lots of happy gays on t...\n",
      "815336583033298944  New Years in Iceland with @olguitasegura @Dian...\n",
      "815337557089193990  The firework here in Malm√∂ at midnight, 20 min...\n",
      "815337887491379200  ‚ô´ She Will Be Loved ‚ô™\\n\\nby @MizzSandraBee\\n\\n...\n",
      "815337982265880577  Happy New Year! üéâ Hopefully 2017 will be bette...\n",
      "...                                                               ...\n",
      "819670411491311616  @csswizardry @nelstrom has 65 of them on https...\n",
      "819670795500851200                                 @ehalmann Oh yess!\n",
      "819671076393336832  ‚ô´ Biscuits ‚ô™\\n\\nby @mynameisFACE\\n\\nhttps://t....\n",
      "819671120483942401                   @cbgb72 please do, beyond gutted\n",
      "819671899617820676  Selina has literally no life (the text is waaa...\n",
      "819672224512831488            @St0mpen Chick, chick! @ThomasBreivik72\n",
      "819672479019008000  @akshit_miglani Sevilla play at home and are a...\n",
      "819672641539862529      You had one job...... https://t.co/LKZ3g0EgvV\n",
      "819672902173945860    @VivGroskop @BBCInOurTime My favourite in ages.\n",
      "819673455209680899  Probably just checking all is prep for Jan 20 ...\n",
      "819673511065255942  Cupcakes are fine BUT SHE LOVES LEXAüòâ https://...\n",
      "819673592568905728  @Dambakuombera me too,I don't feel sorry for e...\n",
      "819674794039934978  #buzzfeed #seanhannity our journalist motto in...\n",
      "819674942639841281                                 baby its you and i\n",
      "819675074626260996  @leslieleeiii @FeministaJones  \\n8. KSA weapon...\n",
      "819675273968943107  ‚ô´ Sight of You ‚ô™\\n\\nby @bijouks\\n\\nhttps://t.c...\n",
      "819675520396914688  @AJStylesOrg Only 17 days until you can #beatu...\n",
      "819676343055110144            @St0mpen Sorry. Hetta  @ThomasBreivik72\n",
      "819676393831329792  ‚ô´ Broken-Hearted Girl ‚ô™\\n\\nby @memyselfandi3_\\...\n",
      "819676492477198338  So uh, I have a friend, who needs a family @So...\n",
      "819676709536628737  Wind 0,7 m/s NE. Barometer 982,0 hPa, Rising s...\n",
      "819678028355817473                             Collab #askjacobandbea\n",
      "819678033900617728  What Samorost 3 exists?!? A weekend project!\\n...\n",
      "819678275354193920    what's ur favorite Disney song? #askjacobandbea\n",
      "819678853782245377  @mariathegerman Will do! gonna send it tomorro...\n",
      "819679005259468802  @paulmasonnews would it be the same all seeing...\n",
      "819679019931226112  Jacob can bea please be your opening act in eu...\n",
      "819679041938718722  I've converted my cadaan friend https://t.co/1...\n",
      "819679122704232449  Simple lunch! Roast beef steak minute with rat...\n",
      "819679253453275137  Interesting! BUT SHE LOVES LEXA https://t.co/P...\n",
      "\n",
      "[10000 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in data:\n",
    "    if \"extended_tweet\" in line:\n",
    "        df = df.append({'tweet_id': line['id'],\n",
    "            'tweet_text':line[\"extended_tweet\"]['full_text']         \n",
    "                       }, ignore_index=True)        \n",
    "    else:\n",
    "        df = df.append({'tweet_id': line['id'],\n",
    "            'tweet_text':line['text']           \n",
    "                       }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('tweet_id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lable = pd.read_csv(\"en10k_markup.txt\",sep=' ',index_col=1,names=[\"lable\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.merge(df,df_lable, how='left',left_index=True,right_index=True)\n",
    "df_final.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>lable</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>815331870015627265</th>\n",
       "      <td>Wind 1,4 m/s ENE. Barometer 1003,2 hPa, Fallin...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815332374909222912</th>\n",
       "      <td>@pasdcheval i did it</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815332387496357889</th>\n",
       "      <td>Happy New Year 2017! https://t.co/UFob5hzO5o</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815332527254732800</th>\n",
       "      <td>Happy new Year from sweden</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815332597886840834</th>\n",
       "      <td>Happy New Years!!!! üí´</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           tweet_text  lable\n",
       "tweet_id                                                                    \n",
       "815331870015627265  Wind 1,4 m/s ENE. Barometer 1003,2 hPa, Fallin...    1.0\n",
       "815332374909222912                               @pasdcheval i did it    0.0\n",
       "815332387496357889       Happy New Year 2017! https://t.co/UFob5hzO5o    0.0\n",
       "815332527254732800                         Happy new Year from sweden    0.0\n",
       "815332597886840834                              Happy New Years!!!! üí´    0.0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF TO EXCEL\n",
    "\n",
    "writer = ExcelWriter('PythonSaeideh.xlsx')\n",
    "df_final.to_excel(writer,'Sheet5')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Porter stemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemmer = PorterStemmer(mode=\"MARTIN_EXTENSIONS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemmer.stem('swimming')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snowball stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'swim'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stemmer.stem('swimming')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "    tweet = re.sub('http\\S+\\s*', 'xurlx', tweet)  \n",
    "    tweet = re.sub('\\d+', 'xnumberx', tweet)  \n",
    "    tweet = re.sub('#\\S+', 'xhashtagx', tweet) \n",
    "    tweet = re.sub('@\\S+', 'xuserx', tweet) \n",
    "    tweet = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', tweet)\n",
    "    tweet = re.sub('\\s+', ' ', tweet)  \n",
    "    return map(lambda x:stemmer.stem(x),tweet.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id\n",
       "815331870015627265    [wind, xnumberx, xnumberx, m, s, ene, baromet,...\n",
       "815332374909222912                                 [xuserx, i, did, it]\n",
       "815332387496357889                  [happi, new, year, xnumberx, xurlx]\n",
       "815332527254732800                     [happi, new, year, from, sweden]\n",
       "815332597886840834                                [happi, new, year, üí´]\n",
       "815333076070965249     [xuserx, xuserx, he, is, a, hunk, papi, nowaday]\n",
       "815333369751990276                           [xuserx, happi, new, year]\n",
       "815333438374998016    [xuserx, happi, new, year, and, happi, xnumber...\n",
       "815333549289209856    [not, onli, have, the, firework, been, go, off...\n",
       "815333756932333569    [i, know, it, probabl, didn, t, come, out, in,...\n",
       "815333875077566465              [when, you, p, r, o, g, r, a, m, xurlx]\n",
       "815333969801728001                     [happi, new, year, bitch, xurlx]\n",
       "815334054790893568                 [xuserx, same, to, you, amp, famili]\n",
       "815334109656522753    [guess, who, been, on, stage, xuserx, xhashtag...\n",
       "815334157626834944                         [happi, new, year, üòç, xurlx]\n",
       "815334231454994432         [happi, new, year, ya, ll, üéá, xuserx, xurlx]\n",
       "815334667171794944    [xuserx, same, i, saw, justin, for, the, first...\n",
       "815335361538883584    [gott, nytt, xhashtagx, imperi, ftw, drink, a,...\n",
       "815335396745900032    [wind, xnumberx, xnumberx, m, s, nne, baromet,...\n",
       "815335415708192768    [xnumberx, user, and, xnumberx, tweet, xnumber...\n",
       "815335418652540928    [xnumberx, verifi, account, help, to, turn, go...\n",
       "815335693539045376    [‚ú®üí•, happi, new, year, everyon, ‚òÑÔ∏èüí•, varatunve...\n",
       "815335831011467265    [xuserx, the, last, thing, i, said, in, xnumbe...\n",
       "815336030014414848                               [happi, new, year, üòöüéâ]\n",
       "815336278938030080      [sista, godsaken, my, home, tvxnumberxb, xurlx]\n",
       "815336343941300228    [may, the, new, year, bring, lot, of, happi, g...\n",
       "815336583033298944    [new, year, in, iceland, with, xuserx, xuserx,...\n",
       "815337557089193990    [the, firework, here, in, malm√∂, at, midnight,...\n",
       "815337887491379200    [‚ô´, she, will, be, love, ‚ô™, by, xuserx, xurlxx...\n",
       "815337982265880577    [happi, new, year, üéâ, hope, xnumberx, will, be...\n",
       "                                            ...                        \n",
       "815727468644601856    [wind, xnumberx, xnumberx, m, s, sw, baromet, ...\n",
       "815728430021046272                 [xuserx, xuserx, say, ew, to, tasti]\n",
       "815728913477406721    [well, i, have, express, a, coupl, of, veri, h...\n",
       "815729846441705472    [i, ve, turn, into, a, sherlock, fan, acc, but...\n",
       "815730319383035908            [beluga, appar, mean, white, in, russian]\n",
       "815730841221533696    [xuserx, xuserx, xuserx, xuserx, hard, work, a...\n",
       "815732501243170816    [wind, xnumberx, xnumberx, m, s, sw, baromet, ...\n",
       "815732988398989320    [wish, hardaway, jr, was, still, on, the, knic...\n",
       "815733248760381440    [a, lill, wind, and, that, pussi, will, b, out...\n",
       "815733966649049088    [the, big, collect, never, end, self, humili, ...\n",
       "815734311768952836    [oh, wow, if, i, was, ur, gf, n, u, want, to, ...\n",
       "815734450617282560    [‚ô´, the, sun, goe, down, live, it, up, xnumber...\n",
       "815734730691923968    [can, t, sleep, so, i, m, watch, this, for, th...\n",
       "815736277417033728    [wind, xnumberx, xnumberx, m, s, sw, baromet, ...\n",
       "815736855626924032                          [xuserx, give, me, the, rn]\n",
       "815738337990479872    [i, need, a, vaction, away, from, allt, och, a...\n",
       "815738792002785280    [wind, xnumberx, xnumberx, m, s, w, baromet, x...\n",
       "815739699025375232             [xuserx, you, ve, taken, over, my, soul]\n",
       "815740055314661376    [head, over, to, spotifi, folk, and, listen, t...\n",
       "815740195974905864    [xuserx, so, versatil, from, pleas, releas, me...\n",
       "815741026493026304    [xuserx, no, that, nice, just, remov, the, gam...\n",
       "815741160455020544                 [‚ô´, neon, ‚ô™, by, xuserx, xurlxxurlx]\n",
       "815741195636899840    [xuserx, xuserx, you, re, not, go, to, get, ne...\n",
       "815741248933863428    [mad, i, didn, t, fall, asleep, befor, my, sis...\n",
       "815742033650388992          [whi, the, bore, background, xuserx, xurlx]\n",
       "815742500744863744              [xuserx, they, are, so, cute, üòª, xurlx]\n",
       "815743152459919360    [scatter, cloud, gt, mist, temperatur, down, x...\n",
       "815743310434365440                    [xuserx, ever, come, to, denmark]\n",
       "815743675963736064    [xuserx, where, do, you, keep, all, the, soul,...\n",
       "815743896168910852             [xuserx, how, rad, of, a, dad, are, you]\n",
       "Name: tweet_text, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet_text'].head(1000).apply(clean_tweet).apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF TO EXCEL\n",
    "\n",
    "writer = ExcelWriter('PythonWithClean.xlsx')\n",
    "df['tweet_text'].head(1000).apply(clean_tweet).apply(list).to_excel(writer,'Sheet1')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_final['tweet_text']\n",
    "y = df_final['lable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes classifier (NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=clean_tweet)),  \n",
    "    ('classifier', MultinomialNB()),  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9044896755162242\n"
     ]
    }
   ],
   "source": [
    "recall = cross_val_score(pipeline, X, y, cv=10,scoring='recall')\n",
    "print(recall.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9746900234634277\n"
     ]
    }
   ],
   "source": [
    "precision = cross_val_score(pipeline, X, y, cv=10,scoring='precision')\n",
    "print(precision.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9732007954007953\n"
     ]
    }
   ],
   "source": [
    "accuracy = cross_val_score(pipeline, X, y, cv=10,scoring='accuracy')\n",
    "print(accuracy.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7696   53]\n",
      " [ 215 2036]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix is not a score, it is a kind of summary of what happened during evaluation.\n",
    "\n",
    "y_pred = cross_val_predict(pipeline, X , y, cv=10)\n",
    "conf_mat = confusion_matrix(y, y_pred)\n",
    "print(conf_mat)\n",
    "\n",
    "#[row, column]\n",
    "TP = conf_mat[1, 1]\n",
    "TN = conf_mat[0, 0]\n",
    "FP = conf_mat[0, 1]\n",
    "FN = conf_mat[1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! [small confusion matrix](images?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine(SVM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=clean_tweet)),  \n",
    "    ('classifier', SVC(gamma='scale')),  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8831642084562439\n"
     ]
    }
   ],
   "source": [
    "recall = cross_val_score(pipeline, X, y, cv=10,scoring='recall')\n",
    "print(recall.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9984847454133169\n"
     ]
    }
   ],
   "source": [
    "precision = cross_val_score(pipeline, X, y, cv=10,scoring='precision')\n",
    "print(precision.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest(RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=clean_tweet)),  \n",
    "    ('classifier', RandomForestClassifier(n_estimators=600)),  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9662340216322518\n"
     ]
    }
   ],
   "source": [
    "recall = cross_val_score(pipeline, X, y, cv=10,scoring='recall')\n",
    "print(recall.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9986188136188137\n"
     ]
    }
   ],
   "source": [
    "precision = cross_val_score(pipeline, X, y, cv=10,scoring='precision')\n",
    "print(precision.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
